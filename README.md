# SoMoS

**SoMoS** (pronounced /ˈsoʊ.moʊs/) - *"(we) are"* - is a collaborative art experience where participants use their phones as instruments to collectively create generative audio-visual performances.

## Overview

SoMoS transforms smartphones into interactive instruments that control both sound and visuals. Participants use their phone's motion sensors (accelerometer, gyroscope) and microphone to influence a shared stage display, creating an emergent collective performance.

## Features

- **Multi-device Collaboration**: Multiple participants can join a single performance session
- **Motion-based Interaction**: Uses device orientation and motion sensors for expressive control
- **Audio Input**: Microphone input for additional performance dimensions
- **Real-time Synthesis**: Built-in drone synthesizer with harmonic overtones and waveform morphing
- **Visual Display**: Generative p5.js visualizations driven by participant input
- **Session Management**: QR code-based joining system for easy participant onboarding
- **WebSocket Communication**: Low-latency binary protocol for sensor data streaming

## Architecture

The application consists of three main components:

1. **Server** (`server.js`): Express + WebSocket server managing performance instances
2. **Stage View**: Display interface showing visuals and coordinating the performance
3. **Musician View**: Mobile interface for participants to control the performance

### Technology Stack

- **Backend**: Node.js, Express, WebSocket (ws)
- **Frontend**: Vanilla JavaScript, p5.js for visuals
- **Audio**: Tone.js for synthesis
- **Session Management**: express-session with cookie-based authentication

## Installation

### Prerequisites

- Node.js (v18 or higher recommended)
- pnpm package manager

### Setup

1. Clone the repository:
```bash
git clone <repository-url>
cd creative-coding-final-project-group-9-o
```

2. Install dependencies:
```bash
pnpm install
```

3. Start the development server:
```bash
pnpm dev
```

4. Open your browser and navigate to:
```
http://localhost:3215
```

## Usage

### Starting a Performance

1. **Create Instance**: Open the application and click "Begin" to create a new performance instance
2. **Share QR Code**: Participants scan the displayed QR code with their phones
3. **Grant Permissions**: Participants must grant motion sensor and microphone permissions on their devices
4. **Open Stage View**: Click "Open Stage View" to launch the visual display
5. **Perform**: Participants can now move, shake, and interact with their phones to affect the performance

### For Participants (Musicians)

- **Motion Control**: Tilt and rotate your phone to influence the performance
- **Shake Gestures**: Sharp movements create dynamic effects
- **Audio Input**: Speak, sing, or make sounds near your phone's microphone
- **Stay Connected**: Keep the browser tab active for best performance

### For Stage Operators

- The stage view displays real-time visuals generated by all connected participants
- Monitor connected device count in the instructions panel
- The stage automatically receives and processes data from all musicians

## Project Structure

```
.
├── server.js                 # Main server and WebSocket handler
├── src/
│   ├── ensemble.js          # Instance management and connection handling
│   └── logger.js            # Pino-based logging
├── public/
│   ├── js/
│   │   ├── musician.js      # Musician client logic
│   │   ├── stage.js         # Stage client logic
│   │   ├── sensor-manager.js # Device sensor handling
│   │   ├── motion-tracker.js # Motion processing
│   │   ├── synth.js         # DroneSynth audio engine
│   │   ├── protocol.js      # Binary protocol encoding/decoding
│   │   └── p5/              # p5.js sketches
│   ├── css/                 # Stylesheets
│   └── assets/              # Images and icons
└── views/
    ├── index.html           # Landing and instructions page
    ├── musician.html        # Participant interface
    └── stage.html           # Display interface
```

## API Endpoints

### HTTP Routes

- `GET /` - Landing page and instance creation
- `GET /join?instance=<id>` - Join a performance instance
- `GET /musician` - Musician control interface (protected)
- `GET /stage` - Stage display interface (protected)
- `POST /api/instance/new` - Create new performance instance
- `GET /api/instance` - Get current instance information

### WebSocket Protocol

The application uses a hybrid JSON/binary protocol:

- **JSON Messages**: Control messages (join, leave, identify)
- **Binary Messages**: High-frequency sensor data from musicians to stage

Binary sensor data format (from musicians):
- Session ID (variable length UTF-8) + sensor payload
- Sensor payload encoded using `protocol.js` for efficient transmission

## Development

### Debug Views

Debug interfaces are available for development:

- `/musician-debug` - Musician interface with sensor visualizations
- `/stage-debug` - Stage interface with additional debugging info

### Running in Development Mode

```bash
pnpm dev
```

This starts the server with `pino-pretty` for formatted logs.

### Session Management

- Sessions use express-session with cookie-based authentication
- Each performance instance has a unique ID
- Stage sessions use the session ID as instance ID
- Musicians join instances via QR code with instance parameter

## Configuration

### Server Port

Default port is `3215`. To change, modify `server.js:148`:

```javascript
server.listen(3215, () => {
  logger.info('Server is up on port 3215');
});
```

### Cleanup Settings

Instance cleanup happens automatically for inactive sessions:
- Stale timeout: 30 minutes of inactivity
- Cleanup check interval: 5 minutes

Configure in `src/ensemble.js:111-112`

## Sensor Data

### Required Permissions

- **DeviceMotionEvent**: For accelerometer and gyroscope data
- **MediaDevices**: For microphone access

### Supported Sensors

- Accelerometer (linear acceleration)
- Gyroscope (rotation rate)
- Orientation (device orientation angles)
- Microphone (audio input level)

## Browser Compatibility

- **Chrome/Edge**: Full support (recommended)
- **Safari/iOS**: Requires iOS 13+ for motion permissions
- **Firefox**: Full support with user permissions

Note: Motion sensors require HTTPS in production environments.

## Deployment

For production deployment:

1. Use HTTPS (required for motion sensors on most browsers)
2. Configure a process manager (PM2, systemd, etc.)
3. Set appropriate session secrets (currently random on startup)
4. Consider using a Redis-backed session store for multi-instance deployments

## License

ISC

## Credits

Creative Coding Final Project - Group 9
